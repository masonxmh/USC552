{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b352809",
   "metadata": {},
   "source": [
    "<center><h1>DSCI-552 HOMEWORK 5</h1><center>\n",
    "<br>\n",
    "<center><font size=\"4\"></font></center>\n",
    "<center><font size=\"3\"><strong>Mason(Mohan) Xing</font></center>\n",
    "<center><font size=\"3\"><strong>USCID:\t6880083372</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "647c0858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsci552\n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import urllib\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, multilabel_confusion_matrix, silhouette_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# check the environment\n",
    "print (os.environ['CONDA_DEFAULT_ENV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aa1408",
   "metadata": {},
   "source": [
    "# 1. Multi-class and Multi-Label Classification Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4712763",
   "metadata": {},
   "source": [
    "## 1(a) Download the Anuran Calls (MFCCs) Data Set \n",
    "from: https://archive.ics.uci.edu/ml/datasets/Anuran+Calls+%28MFCCs%29. Choose 70% of the data randomly as the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43771fd5",
   "metadata": {},
   "source": [
    "Note: The dataset has already been downloaded do not need to run the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2db0b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download original dataset\n",
    "# url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00406/Anuran%20Calls%20(MFCCs).zip\"\n",
    "# datafile = \"../data/Anuran Calls (MFCCs).zip\"\n",
    "# urllib.request.urlretrieve(url, datafile)\n",
    "\n",
    "# with zipfile.ZipFile(datafile, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(\"../data/Anuran Calls (MFCCs)\")\n",
    "#     zip_ref.close()\n",
    "\n",
    "# os.remove(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1649c625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7195 entries, 0 to 7194\n",
      "Data columns (total 26 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   MFCCs_ 1  7195 non-null   float64\n",
      " 1   MFCCs_ 2  7195 non-null   float64\n",
      " 2   MFCCs_ 3  7195 non-null   float64\n",
      " 3   MFCCs_ 4  7195 non-null   float64\n",
      " 4   MFCCs_ 5  7195 non-null   float64\n",
      " 5   MFCCs_ 6  7195 non-null   float64\n",
      " 6   MFCCs_ 7  7195 non-null   float64\n",
      " 7   MFCCs_ 8  7195 non-null   float64\n",
      " 8   MFCCs_ 9  7195 non-null   float64\n",
      " 9   MFCCs_10  7195 non-null   float64\n",
      " 10  MFCCs_11  7195 non-null   float64\n",
      " 11  MFCCs_12  7195 non-null   float64\n",
      " 12  MFCCs_13  7195 non-null   float64\n",
      " 13  MFCCs_14  7195 non-null   float64\n",
      " 14  MFCCs_15  7195 non-null   float64\n",
      " 15  MFCCs_16  7195 non-null   float64\n",
      " 16  MFCCs_17  7195 non-null   float64\n",
      " 17  MFCCs_18  7195 non-null   float64\n",
      " 18  MFCCs_19  7195 non-null   float64\n",
      " 19  MFCCs_20  7195 non-null   float64\n",
      " 20  MFCCs_21  7195 non-null   float64\n",
      " 21  MFCCs_22  7195 non-null   float64\n",
      " 22  Family    7195 non-null   object \n",
      " 23  Genus     7195 non-null   object \n",
      " 24  Species   7195 non-null   object \n",
      " 25  RecordID  7195 non-null   int64  \n",
      "dtypes: float64(22), int64(1), object(3)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "      <th>RecordID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152936</td>\n",
       "      <td>-0.105586</td>\n",
       "      <td>0.200722</td>\n",
       "      <td>0.317201</td>\n",
       "      <td>0.260764</td>\n",
       "      <td>0.100945</td>\n",
       "      <td>-0.150063</td>\n",
       "      <td>-0.171128</td>\n",
       "      <td>0.124676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108351</td>\n",
       "      <td>-0.077623</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.057684</td>\n",
       "      <td>0.118680</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171534</td>\n",
       "      <td>-0.098975</td>\n",
       "      <td>0.268425</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.268353</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>-0.222475</td>\n",
       "      <td>-0.207693</td>\n",
       "      <td>0.170883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090974</td>\n",
       "      <td>-0.056510</td>\n",
       "      <td>-0.035303</td>\n",
       "      <td>0.020140</td>\n",
       "      <td>0.082263</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152317</td>\n",
       "      <td>-0.082973</td>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.276014</td>\n",
       "      <td>0.189867</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.242234</td>\n",
       "      <td>-0.219153</td>\n",
       "      <td>0.232538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050691</td>\n",
       "      <td>-0.023590</td>\n",
       "      <td>-0.066722</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.077162</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.224392</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.329432</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>-0.194347</td>\n",
       "      <td>-0.098181</td>\n",
       "      <td>0.270375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136009</td>\n",
       "      <td>-0.177037</td>\n",
       "      <td>-0.130498</td>\n",
       "      <td>-0.054766</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>-0.068345</td>\n",
       "      <td>0.306967</td>\n",
       "      <td>0.330923</td>\n",
       "      <td>0.249144</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>-0.265423</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048885</td>\n",
       "      <td>-0.053074</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>0.108610</td>\n",
       "      <td>0.079244</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "0       1.0  0.152936 -0.105586  0.200722  0.317201  0.260764  0.100945   \n",
       "1       1.0  0.171534 -0.098975  0.268425  0.338672  0.268353  0.060835   \n",
       "2       1.0  0.152317 -0.082973  0.287128  0.276014  0.189867  0.008714   \n",
       "3       1.0  0.224392  0.118985  0.329432  0.372088  0.361005  0.015501   \n",
       "4       1.0  0.087817 -0.068345  0.306967  0.330923  0.249144  0.006884   \n",
       "\n",
       "   MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_17  MFCCs_18  MFCCs_19  MFCCs_20  \\\n",
       "0 -0.150063 -0.171128  0.124676  ... -0.108351 -0.077623 -0.009568  0.057684   \n",
       "1 -0.222475 -0.207693  0.170883  ... -0.090974 -0.056510 -0.035303  0.020140   \n",
       "2 -0.242234 -0.219153  0.232538  ... -0.050691 -0.023590 -0.066722 -0.025083   \n",
       "3 -0.194347 -0.098181  0.270375  ... -0.136009 -0.177037 -0.130498 -0.054766   \n",
       "4 -0.265423 -0.172700  0.266434  ... -0.048885 -0.053074 -0.088550 -0.031346   \n",
       "\n",
       "   MFCCs_21  MFCCs_22           Family      Genus         Species  RecordID  \n",
       "0  0.118680  0.014038  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "1  0.082263  0.029056  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "2  0.099108  0.077162  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "3 -0.018691  0.023954  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "4  0.108610  0.079244  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data into dataframe\n",
    "data_original =  pd.read_csv(\"../data/Anuran Calls (MFCCs)/Frogs_MFCCs.csv\")\n",
    "data_original.info()\n",
    "data_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af477587",
   "metadata": {},
   "source": [
    "* Choose 70% of the data randomly as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00a16aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size:  (5036, 26)\n",
      "Test Set Size:  (2159, 26)\n"
     ]
    }
   ],
   "source": [
    "# check the train/test dataframe spec\n",
    "train, test = train_test_split(data_original, test_size=0.3, random_state = 42)\n",
    "print(\"Training Set Size: \", train.shape)\n",
    "print(\"Test Set Size: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ace38c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data 'Family' class:\n",
      "Leptodactylidae    4420\n",
      "Hylidae            2165\n",
      "Dendrobatidae       542\n",
      "Bufonidae            68\n",
      "Name: Family, dtype: int64\n",
      "******************************\n",
      "Train data 'Family' class:\n",
      "Leptodactylidae    3073\n",
      "Hylidae            1542\n",
      "Dendrobatidae       380\n",
      "Bufonidae            41\n",
      "Name: Family, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if target class missing in training set\n",
    "print(f\"Original data 'Family' class:\\n{data_original.Family.value_counts()}\")\n",
    "print(\"*\"*30)\n",
    "print(f\"Train data 'Family' class:\\n{train.Family.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5851ae73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data 'Genus' class:\n",
      "Adenomera        4150\n",
      "Hypsiboas        1593\n",
      "Ameerega          542\n",
      "Dendropsophus     310\n",
      "Leptodactylus     270\n",
      "Scinax            148\n",
      "Osteocephalus     114\n",
      "Rhinella           68\n",
      "Name: Genus, dtype: int64\n",
      "******************************\n",
      "Train data 'Genus' class:\n",
      "Adenomera        2899\n",
      "Hypsiboas        1125\n",
      "Ameerega          380\n",
      "Dendropsophus     226\n",
      "Leptodactylus     174\n",
      "Scinax            111\n",
      "Osteocephalus      80\n",
      "Rhinella           41\n",
      "Name: Genus, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if target class missing in training set\n",
    "print(f\"Original data 'Genus' class:\\n{data_original.Genus.value_counts()}\")\n",
    "print(\"*\"*30)\n",
    "print(f\"Train data 'Genus' class:\\n{train.Genus.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc9f331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data 'Species' class:\n",
      "AdenomeraHylaedactylus    3478\n",
      "HypsiboasCordobae         1121\n",
      "AdenomeraAndre             672\n",
      "Ameeregatrivittata         542\n",
      "HypsiboasCinerascens       472\n",
      "HylaMinuta                 310\n",
      "LeptodactylusFuscus        270\n",
      "ScinaxRuber                148\n",
      "OsteocephalusOophagus      114\n",
      "Rhinellagranulosa           68\n",
      "Name: Species, dtype: int64\n",
      "******************************\n",
      "Train data 'Species' class:\n",
      "AdenomeraHylaedactylus    2447\n",
      "HypsiboasCordobae          788\n",
      "AdenomeraAndre             452\n",
      "Ameeregatrivittata         380\n",
      "HypsiboasCinerascens       337\n",
      "HylaMinuta                 226\n",
      "LeptodactylusFuscus        174\n",
      "ScinaxRuber                111\n",
      "OsteocephalusOophagus       80\n",
      "Rhinellagranulosa           41\n",
      "Name: Species, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if target class missing in training set\n",
    "print(f\"Original data 'Species' class:\\n{data_original.Species.value_counts()}\")\n",
    "print(\"*\"*30)\n",
    "print(f\"Train data 'Species' class:\\n{train.Species.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d87285",
   "metadata": {},
   "source": [
    "The above results the training data does not miss any class within each label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb7b4af",
   "metadata": {},
   "source": [
    "## 1(b) Each instance has three labels: \n",
    "Families, Genus, and Species. Each of the labels has multiple classes. We wish to solve a multi-class and multi-label problem. One of the most important approaches to multi-label classification is to train a classifier for each label (binary relevance). We first try this approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2204061b",
   "metadata": {},
   "source": [
    "### 1(b) i. Research exact match and hamming score/ loss methods for evaluating multi-label classification and use them in evaluating the classifiers in this problem.\n",
    "ref: https://medium.datadriveninvestor.com/a-survey-of-evaluation-metrics-for-multilabel-classification-bb16e8cd41cd<br>\n",
    "ref: https://www.linkedin.com/pulse/hamming-score-multi-label-classification-chandra-sharat/ <br>\n",
    "ref: https://mmuratarat.github.io/2020-01-25/multilabel_classification_metrics<br>\n",
    "ref: A Literature Survey on Algorithms for Multi-label Learning, by Mohammad Sorower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ae7b4c",
   "metadata": {},
   "source": [
    "<strong>Exact Match</strong><br>\n",
    "* The Exact Match Ratio evaluation metric extends the concept the accuracy from the single-label classification problem to a multi-label classification problem.\n",
    "* One of the drawbacks of using EMR is that is does not account for partially correct labels.\n",
    "\n",
    "<strong>Hamming loss Methods</strong><br>\n",
    "* Hamming Loss reports how many times on average, the relevance of an example to a class label is incorrectly predicted. Therefore, hamming loss takes into account the prediction error (an incorrect label is predicted) and the missing error (a relevant label not predicted), normalized over total number of classes and total number of examples.\n",
    "\n",
    "<strong>Hamming Score Methods</strong><br>\n",
    "* Calculation is based on correctly predicted label intersection over labels union\n",
    "* If the number of the prediction labels is the same as true labels it can be 1-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "820e0bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to calculate exact match ratio\n",
    "def emr(y_true, y_pred): # y_true, y_pred has to be dataframe\n",
    "    '''\n",
    "    y_true, y_pred have to be dataframes \n",
    "    \n",
    "    '''\n",
    "    result = {}\n",
    "    match = 0\n",
    "    for true, pred in zip(y_true.values, y_pred.values):\n",
    "        if np.array_equal(true, pred) == True: #test if it is exact match array\n",
    "            match+=1\n",
    "    \n",
    "    result['match_ratio'] = match / y_true.shape[0]\n",
    "    result['miss_ratio'] =  (y_true.shape[0]-match) / y_true.shape[0]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed0804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to calculate hamming loss and hamming score\n",
    "def hamming(y_true, y_pred): \n",
    "    '''\n",
    "    y_true, y_pred have to be dataframes\n",
    "    \n",
    "    '''\n",
    "    result = {}\n",
    "    miss_match = 0\n",
    "    temp_a = None\n",
    "    temp = 0\n",
    "    for true, pred in zip(y_true.values, y_pred.values): \n",
    "        r = (true == pred) # predicted label in boolean\n",
    "#         t = [True, True, True] # true label in boolean\n",
    "#         temp_a = sum(np.logical_and(t, r)) / sum(np.logical_or(t, r))\n",
    "#         temp += temp_a\n",
    "        # total partial miss match\n",
    "        miss_match += true.shape[0]-np.sum(r)\n",
    "        \n",
    "    loss = miss_match / ( y_true.shape[0]*y_true.shape[1] )\n",
    "    score = 1-loss # based on Piazza TA`s explanation\n",
    "    distance =  miss_match / y_true.shape[0]\n",
    "    \n",
    "    result['hamming_score'] = score\n",
    "    result['hamming_loss'] = loss\n",
    "    result['hamming_distance'] = distance\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94ad189",
   "metadata": {},
   "source": [
    "### 1(b) ii. Train a SVM for each of the labels, using Gaussian kernels and one versus all classifiers. Determine the weight of the SVM penalty and the width of the Gaussian Kernel using 10 fold cross validation.1 You are welcome to try to solve the problem with both standardized and raw attributes and report the results.\n",
    "ref: https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4079fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X, y split function\n",
    "def xy_split(df):\n",
    "    \n",
    "    X = df.iloc[:,:-4] \n",
    "    y = df.iloc[: , -4:-1]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec3e59b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to prepare training and testing data\n",
    "def data_prepare(tr, ts, std=False):      \n",
    "        \n",
    "    X_tr, y_tr = xy_split(tr)\n",
    "    X_ts, y_ts = xy_split(ts)\n",
    "    \n",
    "    if std == True:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_tr)\n",
    "        X_tr_std = pd.DataFrame(scaler.transform(X_tr), columns=X_tr.columns, index=y_tr.index)\n",
    "        X_ts_std = pd.DataFrame(scaler.transform(X_ts), columns=X_ts.columns, index=y_ts.index)\n",
    "        \n",
    "        return X_tr_std, X_ts_std, y_tr, y_ts \n",
    "    \n",
    "    else:\n",
    "\n",
    "        return X_tr, X_ts, y_tr, y_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d20e8608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to print out classifer results:\n",
    "def evaluation(y_true, y_pred):\n",
    "    \n",
    "    y_test_em = emr(y_test, y_pred)['match_ratio']\n",
    "    y_test_h_score = hamming(y_test, y_pred)['hamming_score']\n",
    "    y_test_h_loss = hamming(y_test, y_pred)['hamming_loss']\n",
    "    \n",
    "    result_df = pd.DataFrame({\"Exact Match Ratio\": [y_test_em],\n",
    "                              \"Hamming Score\": [y_test_h_score],\n",
    "                              \"Hamming Loss\": [y_test_h_loss]})\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3ee52c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_prepare(train, test)\n",
    "\n",
    "# Encoding the variable\n",
    "label_object = {}\n",
    "for col in y_train:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train[col])\n",
    "    y_train[col] = le.transform(y_train[col])\n",
    "    y_test[col] = le.transform(y_test[col])\n",
    "    label_object[col] = le\n",
    "    \n",
    "# label_object['col'].inverse_transform(y_train['col']) # inverse encode label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49952c0",
   "metadata": {},
   "source": [
    "#### - Raw Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61432fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define SVM model tuning hyperparameters\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "parameters = {'C':np.logspace(-3,6,10), \n",
    "              'gamma': np.linspace(2.1,6,40) #usually linear\n",
    "             }\n",
    "svc = SVC(kernel = 'rbf', decision_function_shape='ovr')\n",
    "clf = GridSearchCV(estimator = svc,\n",
    "                   param_grid = parameters, \n",
    "                   scoring='accuracy', \n",
    "                   cv=skf, \n",
    "                   n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce0aaece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [06:32<00:00, 130.96s/it]\n"
     ]
    }
   ],
   "source": [
    "# Training Model and Predict labels\n",
    "temp_dict = {}\n",
    "y_test_pred_dict = {}\n",
    "Cs = []\n",
    "gammas = []\n",
    "scores = []\n",
    "for c in tqdm(y_train.columns):\n",
    "    clf.fit(X_train, y_train[c])\n",
    "    y_test_pred_dict[c] = clf.predict(X_test)\n",
    "    \n",
    "    Cs.append(clf.best_estimator_.C)\n",
    "    gammas.append(clf.best_estimator_.gamma)\n",
    "    scores.append(clf.best_score_)\n",
    "# prediction result df\n",
    "y_test_pred_bii = pd.DataFrame.from_dict(y_test_pred_dict)\n",
    "# best hyperparameters df\n",
    "temp_dict[\"C\"] = Cs\n",
    "temp_dict[\"gamma\"] = gammas\n",
    "temp_dict[\"mean_cv_accuracy\"] = scores\n",
    "best_param_bii = pd.DataFrame.from_dict(temp_dict)\n",
    "best_param_bii.index = y_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f01ba28",
   "metadata": {},
   "source": [
    "* Best Cross Validation Hyperparameters For Each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ad596a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>mean_cv_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.993048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genus</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.991064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Species</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.990867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             C  gamma  mean_cv_accuracy\n",
       "Family   100.0    2.6          0.993048\n",
       "Genus     10.0    2.6          0.991064\n",
       "Species   10.0    2.2          0.990867"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display best classifier hyperparameters\n",
    "best_param_bii"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f9ea6",
   "metadata": {},
   "source": [
    "* Model Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f61a5dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exact Match Ratio</th>\n",
       "      <th>Hamming Score</th>\n",
       "      <th>Hamming Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.987957</td>\n",
       "      <td>0.991817</td>\n",
       "      <td>0.008183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Exact Match Ratio  Hamming Score  Hamming Loss\n",
       "SVM           0.987957       0.991817      0.008183"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display evaluation results\n",
    "df_bii = evaluation(y_test, y_test_pred_bii)\n",
    "df_bii.index = ['SVM']\n",
    "df_bii"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3992338f",
   "metadata": {},
   "source": [
    "#### - Standardized Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fd2243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define SVM model tuning hyperparameters\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "steps = []\n",
    "steps = [('scaler', StandardScaler()), ('SVM', SVC(kernel = 'rbf', decision_function_shape='ovr'))]\n",
    "pipeline = Pipeline(steps)\n",
    "parameters_std = {'SVM__C':np.logspace(-1, 1, 3), \n",
    "                  'SVM__gamma': np.linspace(0.1, 2, 20) #I reduce the hyperparameter numbers to increase the speed\n",
    "                 }\n",
    "clf_std = GridSearchCV(pipeline,\n",
    "                       param_grid = parameters_std, \n",
    "                       scoring='accuracy', \n",
    "                       cv=skf, \n",
    "                       n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc3ea58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [04:22<00:00, 87.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# Training Model and Predic labels for standardized features\n",
    "temp_dict2 = {}\n",
    "y_test_pred_std_dict = {}\n",
    "Cs_std = []\n",
    "gammas_std = []\n",
    "scores_std = []\n",
    "for c in tqdm(y_train.columns):\n",
    "    \n",
    "    clf_std.fit(X_train, y_train[c])\n",
    "    y_test_pred_std_dict[c] = clf_std.predict(X_test)\n",
    "    \n",
    "    Cs_std.append(clf_std.best_params_['SVM__C'])\n",
    "    gammas_std.append(clf_std.best_params_['SVM__gamma'])\n",
    "    scores_std.append(clf_std.best_score_)\n",
    "# prediction result df    \n",
    "y_test_pred_bii_std = pd.DataFrame.from_dict(y_test_pred_std_dict)\n",
    "# best hyperparameters df\n",
    "temp_dict2[\"C\"] = Cs_std\n",
    "temp_dict2[\"gamma\"] = gammas_std\n",
    "temp_dict2[\"mean_cv_accuracy\"] = scores_std\n",
    "best_param_bii_std = pd.DataFrame.from_dict(temp_dict2)\n",
    "best_param_bii_std.index = y_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c732b81",
   "metadata": {},
   "source": [
    "* Best Cross Validation Hyperparameters For Each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93714719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>mean_cv_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.989277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genus</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.986894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Species</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.984710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            C  gamma  mean_cv_accuracy\n",
       "Family   10.0    0.1          0.989277\n",
       "Genus    10.0    0.1          0.986894\n",
       "Species  10.0    0.1          0.984710"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display best classifier hyperparameters\n",
    "best_param_bii_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba036cd",
   "metadata": {},
   "source": [
    "* Model Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bcc951e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exact Match Ratio</th>\n",
       "      <th>Hamming Score</th>\n",
       "      <th>Hamming Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM std</th>\n",
       "      <td>0.983789</td>\n",
       "      <td>0.988266</td>\n",
       "      <td>0.011734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Exact Match Ratio  Hamming Score  Hamming Loss\n",
       "SVM std           0.983789       0.988266      0.011734"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display evaluation results\n",
    "df_bii_std = evaluation(y_test, y_test_pred_bii_std)\n",
    "df_bii_std.index = ['SVM std']\n",
    "df_bii_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797ec787",
   "metadata": {},
   "source": [
    "### 1(b) iii. Repeat 1(b)ii with L1-penalized SVMs. Remember to standardize the attributes. Determine the weight of the SVM penalty using 10 fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72c118b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define SVM model tuning hyperparameters\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "steps = []\n",
    "steps = [('scaler', StandardScaler()), ('LinearSVC', LinearSVC(penalty = 'l1', multi_class='ovr', dual=False))]\n",
    "pipeline = Pipeline(steps)\n",
    "parameters = {'LinearSVC__C':np.logspace(-3,6,10)}\n",
    "clf_biii = GridSearchCV(pipeline,\n",
    "                        param_grid = parameters, \n",
    "                        scoring='accuracy', \n",
    "                        cv=skf, \n",
    "                        n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb0f9322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:39<00:00, 13.33s/it]\n"
     ]
    }
   ],
   "source": [
    "# Training Model and Predic labels\n",
    "temp_dict3 = {}\n",
    "y_test_pred_biii_dict = {}\n",
    "Cs = []\n",
    "scores = []\n",
    "for c in tqdm(y_train.columns):\n",
    "    \n",
    "    clf_biii.fit(X_train, y_train[c])\n",
    "    y_test_pred_biii_dict[c] = clf_biii.predict(X_test)\n",
    "    \n",
    "    Cs.append(clf_biii.best_params_['LinearSVC__C'])\n",
    "    scores.append(clf_biii.best_score_)\n",
    "# prediction result df   \n",
    "y_test_pred_biii = pd.DataFrame.from_dict(y_test_pred_biii_dict)\n",
    "# best hyperparameters df\n",
    "temp_dict3[\"C\"] = Cs\n",
    "temp_dict3[\"mean_cv_accuracy\"] = scores\n",
    "best_param_biii = pd.DataFrame.from_dict(temp_dict3)\n",
    "best_param_biii.index = y_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37725338",
   "metadata": {},
   "source": [
    "* Best Cross Validation Hyperparameters For Each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b5e355c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>mean_cv_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.941223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genus</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.951750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Species</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.960682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              C  mean_cv_accuracy\n",
       "Family     10.0          0.941223\n",
       "Genus    1000.0          0.951750\n",
       "Species    10.0          0.960682"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display best classifier hyperparameters\n",
    "best_param_biii"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089e8d7f",
   "metadata": {},
   "source": [
    "* Model Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7b88ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exact Match Ratio</th>\n",
       "      <th>Hamming Score</th>\n",
       "      <th>Hamming Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVM std</th>\n",
       "      <td>0.912459</td>\n",
       "      <td>0.943029</td>\n",
       "      <td>0.056971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Exact Match Ratio  Hamming Score  Hamming Loss\n",
       "LinearSVM std           0.912459       0.943029      0.056971"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display evaluation results\n",
    "df_biii = evaluation(y_test, y_test_pred_biii)\n",
    "df_biii.index = ['LinearSVM std']\n",
    "df_biii"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708e6151",
   "metadata": {},
   "source": [
    "### 1(b) iv. Repeat 1(b)iii by using SMOTE or any other method you know to remedy class imbalance. Report your conclusions about the classifiers you trained.\n",
    "ref https://towardsdatascience.com/the-right-way-of-using-smote-with-cross-validation-92a8d09d00c7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2706011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct pipline for tunning hyperparameters\n",
    "pipeline = None\n",
    "pipeline = imbpipeline(steps = [['smote', SMOTE(random_state=42)],\n",
    "                                ['scaler', StandardScaler()],\n",
    "                                ['classifier', LinearSVC(penalty = 'l1', multi_class='ovr', dual=False)]])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "parameters = {'classifier__C':np.logspace(-3,6,10)}\n",
    "clf_biv = GridSearchCV(estimator = pipeline,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = skf,\n",
    "                           n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4dc3665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [04:58<00:00, 99.59s/it] \n"
     ]
    }
   ],
   "source": [
    "# Training Model and Predic labels\n",
    "temp_dict = {}\n",
    "y_test_pred_biv_dict = {}\n",
    "Cs = []\n",
    "scores = []\n",
    "for c in tqdm(y_train.columns):\n",
    "    \n",
    "    clf_biv.fit(X_train, y_train[c])\n",
    "    y_test_pred_biv_dict[c] = clf_biv.predict(X_test)\n",
    "    \n",
    "    Cs.append(clf_biv.best_params_['classifier__C'])\n",
    "    scores.append(clf_biv.best_score_)\n",
    "# prediction result df     \n",
    "y_test_pred_biv = pd.DataFrame.from_dict(y_test_pred_biv_dict)\n",
    "# best hyperparameters df\n",
    "temp_dict[\"C\"] = Cs\n",
    "temp_dict[\"mean_cv_accuracy\"] = scores\n",
    "best_param_biv = pd.DataFrame.from_dict(temp_dict)\n",
    "best_param_biv.index = y_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df446073",
   "metadata": {},
   "source": [
    "* Best Cross Validation Hyperparameters For Each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bd099af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>mean_cv_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.922559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genus</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.914227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Species</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.957906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             C  mean_cv_accuracy\n",
       "Family    10.0          0.922559\n",
       "Genus      1.0          0.914227\n",
       "Species  100.0          0.957906"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param_biv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95bb6fa",
   "metadata": {},
   "source": [
    "* Model Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff6c50ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exact Match Ratio</th>\n",
       "      <th>Hamming Score</th>\n",
       "      <th>Hamming Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SMOTE LinearSVM std</th>\n",
       "      <td>0.855952</td>\n",
       "      <td>0.924348</td>\n",
       "      <td>0.075652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Exact Match Ratio  Hamming Score  Hamming Loss\n",
       "SMOTE LinearSVM std           0.855952       0.924348      0.075652"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display evaluation results\n",
    "df_biv = evaluation(y_test, y_test_pred_biv)\n",
    "df_biv.index = ['SMOTE LinearSVM std']\n",
    "df_biv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f1cd82",
   "metadata": {},
   "source": [
    "* Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1585617f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exact Match Ratio</th>\n",
       "      <th>Hamming Score</th>\n",
       "      <th>Hamming Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.987957</td>\n",
       "      <td>0.991817</td>\n",
       "      <td>0.008183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM std</th>\n",
       "      <td>0.983789</td>\n",
       "      <td>0.988266</td>\n",
       "      <td>0.011734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVM std</th>\n",
       "      <td>0.912459</td>\n",
       "      <td>0.943029</td>\n",
       "      <td>0.056971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE LinearSVM std</th>\n",
       "      <td>0.855952</td>\n",
       "      <td>0.924348</td>\n",
       "      <td>0.075652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Exact Match Ratio  Hamming Score  Hamming Loss\n",
       "SVM                           0.987957       0.991817      0.008183\n",
       "SVM std                       0.983789       0.988266      0.011734\n",
       "LinearSVM std                 0.912459       0.943029      0.056971\n",
       "SMOTE LinearSVM std           0.855952       0.924348      0.075652"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = [df_bii, df_bii_std, df_biii, df_biv]\n",
    "df_report = pd.concat(dfs)\n",
    "df_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dfd2df",
   "metadata": {},
   "source": [
    "* Normalized data by using SVM(Gaussian Kernel) with original normalized data has the highest Exact Match Ratio and Hamming Score\n",
    "* The Standardized data using SVM(Gaussian Kernel) also has a very high exact match ratio and hamming score.\n",
    "* The Standardized data using LinearSVM classifier's perfromance is slightly worse than SVM(Gaussian Kernel)\n",
    "* SMOTE data using LinearSVM has the lowest Exact Match Ratio and Hamming Score, I think this is reasonable, since we create a lot of new training data for this classifier, may create more noise and the bias during training try hard to fit the new training dataset may cause the variance increasing for data prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bff3f0b",
   "metadata": {},
   "source": [
    "### 1(b) v. Extra Practice: Study the Classifier Chain method and apply it to the above problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aaec2a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_svm(base_svm, X_tr, X_ts, y_tr, y_ts, c_array):\n",
    "    \n",
    "    y_pred_dict ={}\n",
    "    y_test_em_list =[]\n",
    "    y_test_h_score_list = []\n",
    "    y_test_h_loss_list = []\n",
    "    temp_dict = {}\n",
    "    \n",
    "    for i in tqdm(range(len(orders))):\n",
    "        chain = ClassifierChain(base_svm, order=c_array[i], cv=10)\n",
    "        y_pred = chain.fit(X_tr, y_tr).predict(X_ts)\n",
    "        y_pred = pd.DataFrame(y_pred, columns=y_tr.columns) \n",
    "\n",
    "        y_test_em_list.append(emr(y_ts, y_pred)['match_ratio'])\n",
    "        y_test_h_score_list.append(hamming(y_ts, y_pred)['hamming_score'])\n",
    "        y_test_h_loss_list.append(hamming(y_ts, y_pred)['hamming_loss'])\n",
    "\n",
    "    temp_dict['exact_match'] = y_test_em_list\n",
    "    temp_dict['hamming_score'] = y_test_h_score_list\n",
    "    temp_dict['hamming_loss'] = y_test_h_loss_list\n",
    "    df_temp = pd.DataFrame.from_dict(temp_dict)\n",
    "        \n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82282056",
   "metadata": {},
   "source": [
    "#### - repeat 1(b)ii  Raw Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac0fe13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:16<00:00,  2.80s/it]\n"
     ]
    }
   ],
   "source": [
    "orders = [[0,1,2], [0,2,1], [1,0,2], [1,2,0], [2,0,1], [2,1,0]]\n",
    "base_svm = SVC(kernel = 'rbf', decision_function_shape='ovr')\n",
    "df_bv_ii = chain_svm(base_svm, X_train, X_test, y_train, y_test, orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "763b3e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best order is:\n",
      "[2, 1, 0]\n",
      "\n",
      "Best result is:\n",
      "exact_match      0.978231\n",
      "hamming_score    0.979775\n",
      "hamming_loss     0.020225\n",
      "Name: 5, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "best_result_bv_ii = df_bv_ii.iloc[df_bv_ii['exact_match'].idxmax()]\n",
    "best_index = df_bv_ii.index.get_loc(best_result_bv_ii.name)\n",
    "print(f\"Best order is:\\n{orders[best_index]}\\n\")\n",
    "print(f\"Best result is:\\n{best_result_bv_ii}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3165de",
   "metadata": {},
   "source": [
    "#### - repeat 1(b)ii  Standardized Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a7ad435",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std, X_test_std, y_train, y_test = data_prepare(train, test, std=True)\n",
    "# Encoding the variable\n",
    "label_object = {}\n",
    "for col in y_train:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train[col])\n",
    "    y_train[col] = le.fit_transform(y_train[col])\n",
    "    y_test[col] = le.transform(y_test[col])\n",
    "    label_object[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "364d41ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:19<00:00,  3.26s/it]\n"
     ]
    }
   ],
   "source": [
    "base_svm = SVC(kernel = 'rbf', decision_function_shape='ovr')\n",
    "df_bv_ii_std = chain_svm(base_svm, X_train_std, X_test_std, y_train, y_test, orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e680773f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best order is:\n",
      "[2, 0, 1]\n",
      "\n",
      "Best result is:\n",
      "exact_match      0.983789\n",
      "hamming_score    0.986413\n",
      "hamming_loss     0.013587\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "best_result_bv_ii_std = df_bv_ii_std.iloc[df_bv_ii_std['exact_match'].idxmax()]\n",
    "best_index = df_bv_ii_std.index.get_loc(best_result_bv_ii_std.name)\n",
    "print(f\"Best order is:\\n{orders[best_index]}\\n\")\n",
    "print(f\"Best result is:\\n{best_result_bv_ii_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb71ce1e",
   "metadata": {},
   "source": [
    "#### - repeat 1(b)iii  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0cb22e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [02:37<00:00, 26.28s/it]\n"
     ]
    }
   ],
   "source": [
    "base_svm = LinearSVC(penalty = 'l1', dual=False)\n",
    "df_bv_iii= chain_svm(base_svm, X_train_std, X_test_std, y_train, y_test, orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "692563fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best order is:\n",
      "[2, 1, 0]\n",
      "\n",
      "Best result is:\n",
      "exact_match      0.932376\n",
      "hamming_score    0.955226\n",
      "hamming_loss     0.044774\n",
      "Name: 5, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "best_result_bv_iii = df_bv_iii.iloc[df_bv_iii['exact_match'].idxmax()]\n",
    "best_index = df_bv_iii.index.get_loc(best_result_bv_iii.name)\n",
    "print(f\"Best order is:\\n{orders[best_index]}\\n\")\n",
    "print(f\"Best result is:\\n{best_result_bv_iii}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ad0dec",
   "metadata": {},
   "source": [
    "#### - repeat 1(b)iv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcabd0a6",
   "metadata": {},
   "source": [
    "### 1(b)vi. Extra Practice: Research how confusion matrices, precision, recall, ROC, and AUC are defined for multi-label classification and compute them for the classifiers you trained in above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef273e35",
   "metadata": {},
   "source": [
    "# 2. K-Means Clustering on a Multi-Class and Multi-Label Data Set\n",
    "<strong>Monte-Carlo Simulation:</strong> Perform the following procedures 50 times, and report\n",
    "the average and standard deviation of the 50 Hamming Distances that you calculate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77cfbd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X, y\n",
    "X, y_original = xy_split(data_original)\n",
    "y = y_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f128150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the variable\n",
    "label_object = {}\n",
    "for col in y:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y[col])\n",
    "    y[col] = le.fit_transform(y[col])\n",
    "    label_object[col] = le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0354f495",
   "metadata": {},
   "source": [
    "## 2(a) Use k-means clustering on the whole Anuran Calls (MFCCs) Data Set \n",
    "(do not split the data into train and test, as we are not performing supervised learning in this exercise). Choose k $\\in$ {1,2,...50} automatically based on one of the methods provided in the slides (CH or Gap Statistics or scree plots or Silhouettes) or anyother method you know. <br>\n",
    "ref: https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5be337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get the optimal K in each MC simulation\n",
    "def get_best_k(X, i):\n",
    "    \n",
    "    silhouette_scores = []\n",
    "    cl_list = []\n",
    "    result = {}\n",
    "    for k in range(1,51):\n",
    "    \n",
    "        kmeans = KMeans(n_clusters=k, random_state=i)\n",
    "        cluster_labels = kmeans.fit_predict(X)\n",
    "        cl_list.append(cluster_labels)\n",
    "        \n",
    "        if k == 1:\n",
    "            silhouette_avg = 0 # since silhouette_score cant have k=1\n",
    "            silhouette_scores.append(silhouette_avg)\n",
    "        else:\n",
    "            silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "            silhouette_scores.append(silhouette_avg)\n",
    "            \n",
    "    index = silhouette_scores.index(max(silhouette_scores))\n",
    "    result['best_k'] = index + 1\n",
    "    result['best_cl'] = cl_list[index]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a295b3",
   "metadata": {},
   "source": [
    "* Sample output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "993c403b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Best K is: 4\n"
     ]
    }
   ],
   "source": [
    "m = 0 # random state/MC run\n",
    "sample_result = get_best_k(X, m)\n",
    "print(\"Selected Best K is:\", sample_result['best_k'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dd8957",
   "metadata": {},
   "source": [
    "## 2(b) In each cluster, determine which family is the majority by reading the true labels. Repeat for genus and species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc3bb70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to find the majority true label in each target\n",
    "def get_majority(y_ori, cl,  i):\n",
    "    '''\n",
    "    y_ori is the original label\n",
    "    cl is cluster labels\n",
    "    i is index: MC run number\n",
    "    '''\n",
    "    y_df = y_ori.copy()\n",
    "    y_df['cluster_label'] = cl\n",
    "    # get the majority true labels for each target column by cluster \n",
    "    df_Family=y_df.groupby('cluster_label')['Family'].agg(pd.Series.mode).to_frame()\n",
    "    df_Genus=y_df.groupby('cluster_label')['Genus'].agg(pd.Series.mode).to_frame()\n",
    "    df_Species=y_df.groupby('cluster_label')['Species'].agg(pd.Series.mode).to_frame()\n",
    "    result_df = pd.concat([df_Family, df_Genus, df_Species], axis=1, ignore_index=True)\n",
    "    result_df.columns = y_ori.columns\n",
    "    # save results in a data frame for (family, genus, species)\n",
    "    index_arrays = [[i,i,i,i], result_df.index]\n",
    "    index_tuples = list(zip(*index_arrays))\n",
    "    index = pd.MultiIndex.from_tuples(index_tuples, names=[\"Run\", \"cluster label\"])\n",
    "    result_df.index = index\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840e34fc",
   "metadata": {},
   "source": [
    "* Sample output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ab639c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run</th>\n",
       "      <th>cluster label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraHylaedactylus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dendrobatidae</td>\n",
       "      <td>Ameerega</td>\n",
       "      <td>Ameeregatrivittata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Hypsiboas</td>\n",
       "      <td>HypsiboasCinerascens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Hypsiboas</td>\n",
       "      <td>HypsiboasCordobae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Family      Genus                 Species\n",
       "Run cluster label                                                    \n",
       "0   0              Leptodactylidae  Adenomera  AdenomeraHylaedactylus\n",
       "    1                Dendrobatidae   Ameerega      Ameeregatrivittata\n",
       "    2                      Hylidae  Hypsiboas    HypsiboasCinerascens\n",
       "    3                      Hylidae  Hypsiboas       HypsiboasCordobae"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate cluster labels\n",
    "df_m = get_majority(y_original, sample_result['best_cl'], m)\n",
    "df_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594c8759",
   "metadata": {},
   "source": [
    "## 2(c) Now for each cluster you have a majority label triplet (family, genus, species). Calculate the average Hamming distance, Hamming score, and Hamming loss between the true labels and the labels assigned by clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b7bcd2",
   "metadata": {},
   "source": [
    "* The function below calculate the hamming metric for each cluster (may not apply in this hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2875ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to evaluate the hamming metrics for each cluster at each MC simulation\n",
    "# def cluster_evaluation(y_tr_cl, y_pred_cl, cluster_labels, i):\n",
    "#     h_cl ={}\n",
    "#     h_dis_cl =[]\n",
    "#     h_score_cl = []\n",
    "#     h_loss_cl = []\n",
    "#     for j in list(set(cluster_labels)):\n",
    "        \n",
    "#         y_tr_temp = y_tr_cl.loc[y_tr_cl.cluster_label==j]\n",
    "#         y_pred_temp = y_pred_cl.loc[y_pred_cl.cluster_label==j]\n",
    "#         # evaluate each cluster by hamming metrics\n",
    "#         h_cl_result = hamming(y_tr_temp[y_original.columns], y_pred_temp[y_original.columns])\n",
    "#         h_dis_cl.append(h_cl_result['hamming_distance'])\n",
    "#         h_score_cl.append(h_cl_result['hamming_score'])\n",
    "#         h_loss_cl.append(h_cl_result['hamming_loss'])\n",
    "        \n",
    "#     h_cl['Ave Hamming Distance'] = h_dis_cl\n",
    "#     h_cl['Ave Hamming Score'] = h_score_cl\n",
    "#     h_cl['Ave Hamming Loss'] = h_loss_cl\n",
    "#     df_h_cl = pd.DataFrame.from_dict(h_cl)\n",
    "#     index_arrays = [[i,i,i,i], df_h_cl.index]\n",
    "#     index_tuples = list(zip(*index_arrays))\n",
    "#     index = pd.MultiIndex.from_tuples(index_tuples, names=[\"Round\", \"cluster label\"])\n",
    "#     df_h_cl.index = index \n",
    "    \n",
    "#     return df_h_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f3af85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to assign major triplet to cluster label\n",
    "def assign_triple(df_majority, cl, i):\n",
    "    '''\n",
    "    df_majority is the result dataframe from part 2b\n",
    "    cl : cluster labels\n",
    "    i : run number\n",
    "    '''\n",
    "    y_pred_dict = {}\n",
    "    for c in df_majority:\n",
    "        y_pred_dict[c] = [df_majority[c].loc[i][x] for x in cl]\n",
    "    y_pred = pd.DataFrame.from_dict(y_pred_dict)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4be27a8",
   "metadata": {},
   "source": [
    "* Sample output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da2d020e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0: Average Hamming Distance:0.6653231410701876, Hamming Score:0.7782256196432707, Hamming Loss: 0.22177438035672922\n"
     ]
    }
   ],
   "source": [
    "sample_prediction = assign_triple(df_m, sample_result['best_cl'], m)\n",
    "h_r = hamming(y_original, sample_prediction)\n",
    "print(f\"Run {m}: Average Hamming Distance:{h_r['hamming_distance']}, Hamming Score:{h_r['hamming_score']}, Hamming Loss: {h_r['hamming_loss']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb08ac",
   "metadata": {},
   "source": [
    "## Monte-Carlo Simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5460880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0: Best k is: 4\n",
      "Run 0: Average Hamming Distance:0.6653231410701876, Hamming Score:0.7782256196432707, Hamming Loss: 0.22177438035672922\n",
      "Run 1: Best k is: 4\n",
      "Run 1: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 2: Best k is: 4\n",
      "Run 2: Average Hamming Distance:0.7357887421820709, Hamming Score:0.7547370859393097, Hamming Loss: 0.24526291406069028\n",
      "Run 3: Best k is: 4\n",
      "Run 3: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 4: Best k is: 4\n",
      "Run 4: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 5: Best k is: 4\n",
      "Run 5: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 6: Best k is: 4\n",
      "Run 6: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 7: Best k is: 4\n",
      "Run 7: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 8: Best k is: 4\n",
      "Run 8: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 9: Best k is: 4\n",
      "Run 9: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 10: Best k is: 4\n",
      "Run 10: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 11: Best k is: 4\n",
      "Run 11: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 12: Best k is: 4\n",
      "Run 12: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 13: Best k is: 4\n",
      "Run 13: Average Hamming Distance:0.6674079221681724, Hamming Score:0.7775306926106093, Hamming Loss: 0.22246930738939077\n",
      "Run 14: Best k is: 4\n",
      "Run 14: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 15: Best k is: 4\n",
      "Run 15: Average Hamming Distance:0.6674079221681724, Hamming Score:0.7775306926106093, Hamming Loss: 0.22246930738939077\n",
      "Run 16: Best k is: 4\n",
      "Run 16: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 17: Best k is: 4\n",
      "Run 17: Average Hamming Distance:0.7011813759555247, Hamming Score:0.7662728746814917, Hamming Loss: 0.23372712531850823\n",
      "Run 18: Best k is: 4\n",
      "Run 18: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 19: Best k is: 4\n",
      "Run 19: Average Hamming Distance:0.6653231410701876, Hamming Score:0.7782256196432707, Hamming Loss: 0.22177438035672922\n",
      "Run 20: Best k is: 4\n",
      "Run 20: Average Hamming Distance:0.7021542738012508, Hamming Score:0.765948575399583, Hamming Loss: 0.23405142460041695\n",
      "Run 21: Best k is: 4\n",
      "Run 21: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 22: Best k is: 4\n",
      "Run 22: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 23: Best k is: 4\n",
      "Run 23: Average Hamming Distance:0.6674079221681724, Hamming Score:0.7775306926106093, Hamming Loss: 0.22246930738939077\n",
      "Run 24: Best k is: 4\n",
      "Run 24: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 25: Best k is: 4\n",
      "Run 25: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 26: Best k is: 4\n",
      "Run 26: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 27: Best k is: 4\n",
      "Run 27: Average Hamming Distance:0.6674079221681724, Hamming Score:0.7775306926106093, Hamming Loss: 0.22246930738939077\n",
      "Run 28: Best k is: 4\n",
      "Run 28: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 29: Best k is: 4\n",
      "Run 29: Average Hamming Distance:0.6664350243224462, Hamming Score:0.7778549918925179, Hamming Loss: 0.22214500810748206\n",
      "Run 30: Best k is: 4\n",
      "Run 30: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 31: Best k is: 4\n",
      "Run 31: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 32: Best k is: 4\n",
      "Run 32: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 33: Best k is: 4\n",
      "Run 33: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 34: Best k is: 4\n",
      "Run 34: Average Hamming Distance:0.5581653926337734, Hamming Score:0.8139448691220755, Hamming Loss: 0.1860551308779245\n",
      "Run 35: Best k is: 4\n",
      "Run 35: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 36: Best k is: 4\n",
      "Run 36: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 37: Best k is: 4\n",
      "Run 37: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 38: Best k is: 4\n",
      "Run 38: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 39: Best k is: 4\n",
      "Run 39: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 40: Best k is: 4\n",
      "Run 40: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 41: Best k is: 4\n",
      "Run 41: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 42: Best k is: 4\n",
      "Run 42: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 43: Best k is: 4\n",
      "Run 43: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 44: Best k is: 4\n",
      "Run 44: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 45: Best k is: 4\n",
      "Run 45: Average Hamming Distance:0.6653231410701876, Hamming Score:0.7782256196432707, Hamming Loss: 0.22177438035672922\n",
      "Run 46: Best k is: 4\n",
      "Run 46: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 47: Best k is: 4\n",
      "Run 47: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n",
      "Run 48: Best k is: 4\n",
      "Run 48: Average Hamming Distance:0.8401667824878388, Hamming Score:0.7199444058373871, Hamming Loss: 0.28005559416261294\n",
      "Run 49: Best k is: 4\n",
      "Run 49: Average Hamming Distance:0.66726893676164, Hamming Score:0.7775770210794533, Hamming Loss: 0.2224229789205467\n"
     ]
    }
   ],
   "source": [
    "# Run Monte Carlo Simulation\n",
    "best_ks = []\n",
    "major_list = []\n",
    "h_distances = []\n",
    "h_scores = []\n",
    "h_losses = []\n",
    "\n",
    "for i in range(0,50):\n",
    "    \n",
    "    # calculate the best k for each simulation\n",
    "    best_result = get_best_k(X, i)\n",
    "    best_ks.append(best_result['best_k'])\n",
    "    # generate cluster labels\n",
    "    cluster_labels = best_result['best_cl']\n",
    "    # get the majority label for each cluster\n",
    "    df_majority = get_majority(y_original, cluster_labels, i)\n",
    "    major_list.append(df_majority)\n",
    "    # assign triplet for each cluster label\n",
    "    y_pred = assign_triple(df_majority, cluster_labels, i)\n",
    "    \n",
    "    # metrics for multilabel classification overall\n",
    "    h_result = hamming(y_original, y_pred)\n",
    "    h_distances.append(h_result['hamming_distance'])\n",
    "    h_scores.append(h_result['hamming_score'])\n",
    "    h_losses.append(h_result['hamming_loss'])\n",
    "    \n",
    "    print(f\"Run {i}: Best k is: {best_result['best_k']}\")\n",
    "    print(f\"Run {i}: Average Hamming Distance:{h_result['hamming_distance']}, Hamming Score:{h_result['hamming_score']}, Hamming Loss: {h_result['hamming_loss']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8923c478",
   "metadata": {},
   "source": [
    "### - Best K Values For 50 Monte-Carlo Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7714dfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K value for all Simulations: {4}\n"
     ]
    }
   ],
   "source": [
    "print(f'Best K value for all Simulations: {set(best_ks)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445cbc9d",
   "metadata": {},
   "source": [
    "### - The majority in each family, genus, and species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f8abf8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run</th>\n",
       "      <th>cluster label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraHylaedactylus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dendrobatidae</td>\n",
       "      <td>Ameerega</td>\n",
       "      <td>Ameeregatrivittata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Hypsiboas</td>\n",
       "      <td>HypsiboasCinerascens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Hypsiboas</td>\n",
       "      <td>HypsiboasCordobae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Hypsiboas</td>\n",
       "      <td>HypsiboasCinerascens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <th>3</th>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Hypsiboas</td>\n",
       "      <td>HypsiboasCordobae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">49</th>\n",
       "      <th>0</th>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraHylaedactylus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Hypsiboas</td>\n",
       "      <td>HypsiboasCinerascens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dendrobatidae</td>\n",
       "      <td>Ameerega</td>\n",
       "      <td>Ameeregatrivittata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Hypsiboas</td>\n",
       "      <td>HypsiboasCordobae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Family      Genus                 Species\n",
       "Run cluster label                                                    \n",
       "0   0              Leptodactylidae  Adenomera  AdenomeraHylaedactylus\n",
       "    1                Dendrobatidae   Ameerega      Ameeregatrivittata\n",
       "    2                      Hylidae  Hypsiboas    HypsiboasCinerascens\n",
       "    3                      Hylidae  Hypsiboas       HypsiboasCordobae\n",
       "1   0                      Hylidae  Hypsiboas    HypsiboasCinerascens\n",
       "...                            ...        ...                     ...\n",
       "48  3                      Hylidae  Hypsiboas       HypsiboasCordobae\n",
       "49  0              Leptodactylidae  Adenomera  AdenomeraHylaedactylus\n",
       "    1                      Hylidae  Hypsiboas    HypsiboasCinerascens\n",
       "    2                Dendrobatidae   Ameerega      Ameeregatrivittata\n",
       "    3                      Hylidae  Hypsiboas       HypsiboasCordobae\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2b = pd.concat(major_list)\n",
    "# sample result display\n",
    "df_2b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1626d764",
   "metadata": {},
   "source": [
    "### - The Average Hamming Distance, Hamming Score, and Hamming Loss for Each Monte-Carlo Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "212e7468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ave_Hamming_Distance</th>\n",
       "      <th>Hamming_Score</th>\n",
       "      <th>Hamming_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.665323</td>\n",
       "      <td>0.778226</td>\n",
       "      <td>0.221774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.735789</td>\n",
       "      <td>0.754737</td>\n",
       "      <td>0.245263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.667408</td>\n",
       "      <td>0.777531</td>\n",
       "      <td>0.222469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.667408</td>\n",
       "      <td>0.777531</td>\n",
       "      <td>0.222469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.701181</td>\n",
       "      <td>0.766273</td>\n",
       "      <td>0.233727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.665323</td>\n",
       "      <td>0.778226</td>\n",
       "      <td>0.221774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.702154</td>\n",
       "      <td>0.765949</td>\n",
       "      <td>0.234051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.667408</td>\n",
       "      <td>0.777531</td>\n",
       "      <td>0.222469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.667408</td>\n",
       "      <td>0.777531</td>\n",
       "      <td>0.222469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.666435</td>\n",
       "      <td>0.777855</td>\n",
       "      <td>0.222145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.558165</td>\n",
       "      <td>0.813945</td>\n",
       "      <td>0.186055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.665323</td>\n",
       "      <td>0.778226</td>\n",
       "      <td>0.221774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.840167</td>\n",
       "      <td>0.719944</td>\n",
       "      <td>0.280056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.667269</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.222423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ave_Hamming_Distance  Hamming_Score  Hamming_loss\n",
       "Run                                                   \n",
       "0                0.665323       0.778226      0.221774\n",
       "1                0.667269       0.777577      0.222423\n",
       "2                0.735789       0.754737      0.245263\n",
       "3                0.667269       0.777577      0.222423\n",
       "4                0.667269       0.777577      0.222423\n",
       "5                0.667269       0.777577      0.222423\n",
       "6                0.667269       0.777577      0.222423\n",
       "7                0.667269       0.777577      0.222423\n",
       "8                0.667269       0.777577      0.222423\n",
       "9                0.667269       0.777577      0.222423\n",
       "10               0.667269       0.777577      0.222423\n",
       "11               0.667269       0.777577      0.222423\n",
       "12               0.667269       0.777577      0.222423\n",
       "13               0.667408       0.777531      0.222469\n",
       "14               0.667269       0.777577      0.222423\n",
       "15               0.667408       0.777531      0.222469\n",
       "16               0.667269       0.777577      0.222423\n",
       "17               0.701181       0.766273      0.233727\n",
       "18               0.667269       0.777577      0.222423\n",
       "19               0.665323       0.778226      0.221774\n",
       "20               0.702154       0.765949      0.234051\n",
       "21               0.667269       0.777577      0.222423\n",
       "22               0.667269       0.777577      0.222423\n",
       "23               0.667408       0.777531      0.222469\n",
       "24               0.667269       0.777577      0.222423\n",
       "25               0.667269       0.777577      0.222423\n",
       "26               0.667269       0.777577      0.222423\n",
       "27               0.667408       0.777531      0.222469\n",
       "28               0.667269       0.777577      0.222423\n",
       "29               0.666435       0.777855      0.222145\n",
       "30               0.667269       0.777577      0.222423\n",
       "31               0.667269       0.777577      0.222423\n",
       "32               0.667269       0.777577      0.222423\n",
       "33               0.667269       0.777577      0.222423\n",
       "34               0.558165       0.813945      0.186055\n",
       "35               0.667269       0.777577      0.222423\n",
       "36               0.667269       0.777577      0.222423\n",
       "37               0.667269       0.777577      0.222423\n",
       "38               0.667269       0.777577      0.222423\n",
       "39               0.667269       0.777577      0.222423\n",
       "40               0.667269       0.777577      0.222423\n",
       "41               0.667269       0.777577      0.222423\n",
       "42               0.667269       0.777577      0.222423\n",
       "43               0.667269       0.777577      0.222423\n",
       "44               0.667269       0.777577      0.222423\n",
       "45               0.665323       0.778226      0.221774\n",
       "46               0.667269       0.777577      0.222423\n",
       "47               0.667269       0.777577      0.222423\n",
       "48               0.840167       0.719944      0.280056\n",
       "49               0.667269       0.777577      0.222423"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize Haming Distance, Hamming Score, and Hamming Loss at each round\n",
    "dict_2c = {}\n",
    "dict_2c['Ave_Hamming_Distance'] =  h_distances\n",
    "dict_2c['Hamming_Score'] = h_scores\n",
    "dict_2c['Hamming_loss'] = h_losses\n",
    "df_2c = pd.DataFrame.from_dict(dict_2c)\n",
    "df_2c.index.name = 'Run'\n",
    "df_2c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f44b86e",
   "metadata": {},
   "source": [
    "* Average Hamming Distance, Hamming Score, Hamming Loss for 50 Monte-Carlo Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6d2eba70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Hamming Distance, Hamming Score, Hamming Loss:\n",
      "\n",
      "Ave_Hamming_Distance    0.671169\n",
      "Hamming_Score           0.776277\n",
      "Hamming_loss            0.223723\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'Average Hamming Distance, Hamming Score, Hamming Loss:\\n\\n{df_2c.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de6f8d2",
   "metadata": {},
   "source": [
    "* Standared Deviation of Hamming Distance for 50 Monte-Carlo Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c42a56a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standared Deviation of Hamming Distance:\n",
      "\n",
      "0.03133457064166664\n"
     ]
    }
   ],
   "source": [
    "print(f'Standared Deviation of Average Hamming Distance:\\n\\n{df_2c.Ave_Hamming_Distance.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07834fd",
   "metadata": {},
   "source": [
    "# 3. ISLR 12.6.2\n",
    "ref: https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html<br>\n",
    "ref: https://stackoverflow.com/questions/36520043/triangle-vs-square-distance-matrix-for-hierarchical-clustering-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53515c36",
   "metadata": {},
   "source": [
    "#### (a) On the basis of this dissimilarity matrix, sketch the dendrogram that results from hierarchically clustering these four observations using complete linkage. Be sure to indicate on the plot the height at which each fusion occurs, as well as the observations corresponding to each leaf in the dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e56ae1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAGGCAYAAAB2a4afAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAibUlEQVR4nO3de5wcZZ3v8c+XhEAIl4jAgEkgCBEMKhHGsKiYWYEl6GJgZQ8BFUExomY9eDviuiKsuIqXc7yAxKhAvEZQ0KCBiLqDIiABDZcAwZgAGQIuIA1MuMQMv/NH1WCl0zPTmXRNT8/zfb9e80pX1dPVv36609+qp7qrFBGYmVm6tmp2AWZm1lwOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIRgBJyyV1DIM6TpF0XT/Lr5L09jIfo477d0o6bUtqaARJh0la0ew6GkFSh6SuZtdhg+cgGOYk3SvpiKp5G30YRsQBEdE55MVtpog4OiIWlPkYksZIOlvSnySty/vvIkmTG/gYWxRGABHx24jYr1E1FeVh94ykJyU9IekWSWdK2qaMx7PW5yBImKTRg7jPqDJqaaAfAW8CTgJ2Ag4EbgEOb2ZRRYPp90GYGxE7AHsAHwJmA4slaQge+3mNfq5D1HfJcRCMAMW9Bklb5Vt/f5b0qKRLJe2cL5ssKSS9U9L9wK/z+ZdJekjS45J+I+mAwrovkXShpMWS1gH/KGmSpMslPZw/xvlV9XxB0mOSVks6ujB/o2EZSe+SdFe+5XqnpIPy+b31984/rs5+OAI4EpgVEUsjYkNEPB4RF0TEt2q0P1vSdwvTvf0zOp8+RdKqvI7Vkt4i6aXAPOBQSd2SKnnbbfLnfb+kv0iaJ2lsvqxDUpekj0p6CLi4ejglfw0/LOm2/HX4oaRtC8v/j6QHJa2VdFpe574D9UlErMv3Ft8EHAq8MV9fPe+Tt+fP5xFJHy/UMjZ/Xzwm6U7gVVX9em/+XG8D1kkaLelNyoYwK/n74KWF9gdJ+mPez5flz/3cfvruBZJ+lr//HstvTyysr1PSuZKuz1+jKyW9UNL3lO0hLVUD9xBHAgfByPN+4FhgBvAi4DHggqo2M4CXAkfl01cBU4DdgD8A36tqfxLwaWAH4AbgZ8B9wGRgArCw0PYQYAWwC/A54FvSpluhkv4VOBs4GdiR7IPq0Xzxn4HDyLbozwG+K2mPOp77EcBNEbGmjrb9kjQO+ApwdL5l/WpgWUTcBZwO3BAR20fE+Pwu5wEvAaYB+5L1y1mFVe4O7AzsBczp42H/FzAT2Bt4BXBKXstM4IP589uX7PXbLBFxP3AzWb9Cfe+T1wL7ke1NnVX48P4ksE/+dxRQ67jPiWShMx54MfAD4AxgV2AxcKWyYbwxwBXAJWT98wOgOvir+24r4OJ8ek/gaeD8qvvMBt5G9jrsQ/a+vThfz135c7BeEeG/YfwH3At0A5XC31PAdVVtjshv3wUcXli2B/A3YDTZB3cAL+7n8cbnbXbKpy8Bvl1YfijwMDC6xn1PAVYWprfL17V7Pt0JnJbfXgL87zr7YBnZVn7vY1zXR7tvAAsHWFexhrOB7xaW9fbPaGBc3tdvBsbWeJ7F/hewDtinqp9W57c7gPXAtoXlHUBX1Wv41sL054B5+e2LgM8Ulu2b17nvQM+xav5C4Bub8T6ZWFh+EzA7v70KmFlYNqfGc3lHYfoTwKWF6a2AB/I+eF1+W4Xl1wHn9tV3NZ7XNOCxquf/8cL0F4GrCtPHkIV60/9/D5c/7xG0hmMjYnzvH/DeftruBVyR74JXyP7D9wBthTbPbzFLGiXps/kQwRNk/4kh26LfpD0wCbgvIjb08fgP9d6IiKfym9vXaDeJbMt/E5JOlrSs8BxeVlVPXx4l+0DbYhGxDjiBbOv/QUk/l7R/H813JQu9Wwo1X53P7/VwRDwzwMM+VLj9FH/vtxex8Wsw2D2eCcBf89v1vE/qree+Go9VXP6iYpuIeC5fPiFf9kDkn9A17gtVfSdpO0lfl3Rf/p79DTBeGx+/+kvh9tM1pmu9J5PlIBh51pANZ4wv/G0bEQ8U2hT/050EzCIbdtiJbGsQsq3cWu3XAHtqyw/arSHbZd+IpL3ItuznAi/Mg++Oqnr68ktgenG8eADryD7Ae+1eXBgRSyLiSLJwuTuvCzbuD4BHyD5cDij0+U4RUfyw2ZLT/D4IFJ/TpM1dgaRJwMHAb/NZ9bxP+qunWMOeNdoUn+9asuDprUX5/R/I1zWhaviw+vlV992HyIasDomIHcn2KqC+94jV4CAYeeYBn84/UJG0q6RZ/bTfAXiWbGt6O+C/Blj/TWT/eT8raZykbSW9ZhB1fhP4sKSDldk3r3kc2X/8h/P6TyXbIxhQRPwSuIZsS/fg/CDlDpJOl/SOGndZBrxO0p6SdgI+1rtAUlt+gHMcWf90k20xQ7Z1OTEf3+7dwv0G8P8k7Zbff4Kko2iMS4FTJb1U0nZsfOyhX/nW8wzgp2Sv3eJ80ea+T6rr+Vh+0HYi8G91tH+jpMMlbU32Qf4scD3Z2H0PMDd/vWYB0wdY3w5kwVtRdoDb4/1byEEw8nwZWAT8QtKTwI1kB3D78m2y3fYHgDvz9n2KiB6yMdZ9gfuBLrIhlM0SEZeRHYD+PvAk8BNg54i4k2xM9wayD9yXA7/bjFUfT/Zh90PgcbK9iXayvYXqGq7J291G9hXTnxUWb0X2gbWWbDhlBn8fkvs1sBx4SNIj+byPAiuBG/Phil+SbbVusYi4iuzA9X/nj3FDvujZfu52fv76/wX4EvBjsnH95/Llm/s+KTqH7D2zGvgF8J0B6l8BvBX4Ktne0zHAMRGxPiLWA/8CvJPsmMxbyV6H/p7bl4Cx+bpuJBuGsy2gjYfmzGy4y7+9cwewTT/HalqWpN+THSi/uNm1pMJ7BGYtQNJx+dctX0D2VdUrR0oISJohafd8aOjtZF+d9Vb+EHIQmLWGd5MdN/kz2Zj6e5pbTkPtB9xKNpT3IeD4iHiwuSWlxUNDZmaJ8x6BmVniHARmZolruTP57bLLLjF58uRmlzGgdevWMW7cuGaXMWK4PxvHfdlYrdKft9xyyyMRsWutZS0XBJMnT+bmm29udhkD6uzspKOjo9lljBjuz8ZxXzZWq/SnpFqnAgE8NGRmljwHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4koNAkkzJa2QtFLSmTWW7yTpSkm3SlqeX5/WzMyGUGlBIGkUcAFwNDAVOFHS1Kpm7wPujIgDgQ7gi70XBDczs6FR5knnpgMrI2IVgKSFwCyyC6T3CmAHSQK2J7tI+Ii4/F4r+P7v7+enyx5odhl1qVSe5sIVNwzc0AbUKn05a9oETjpkz2aXkYQyg2ACsKYw3QUcUtXmfGARsBbYATghIp6rXpGkOcAcgLa2Njo7O8uot6G6u7uHfZ0Lfv809z/5HHvuMPwPFfX09FCpVJpdxojQCn15/5PPUalUeNHTq5pdyoBa4f/6QMoMAtWYV31dzKOAZcDrgX2AayT9NiKe2OhOEfOB+QDt7e3RCqd8bYVT01644gbGj4cfvvvQZpcyoFboz1bRCn15wtezPZaODr83h0KZm4JdwKTC9ESyLf+iU4HLI7MSWA3sX2JNZmZWpcwgWApMkbR3fgB4NtkwUNH9wOEAktqA/YDhvy9oZjaClDY0FBEbJM0FlgCjgIsiYrmk0/Pl84BPAZdIup1sKOmjEfFIWTWZmdmmSr1UZUQsBhZXzZtXuL0W+KcyazAzs/4N/6+LmJlZqRwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJKzUIJM2UtELSSkln1lj+EUnL8r87JPVI2rnMmszMbGOlBYGkUcAFwNHAVOBESVOLbSLi8xExLSKmAR8Dro2Iv5ZVk5mZbarMPYLpwMqIWBUR64GFwKx+2p8I/KDEeszMrIbRJa57ArCmMN0FHFKroaTtgJnA3D6WzwHmALS1tdHZ2dnQQsvQ3d097OusVJ4GGPZ1Qmv0Z6tohb70e3NolRkEqjEv+mh7DPC7voaFImI+MB+gvb09Ojo6GlJgmTo7OxnudV644gYAOjoObXIlA2uF/mwVrdCXfm8OrTKHhrqASYXpicDaPtrOxsNCZmZNUWYQLAWmSNpb0hiyD/tF1Y0k7QTMAH5aYi1mZtaH0oaGImKDpLnAEmAUcFFELJd0er58Xt70OOAXEbGurFrMzKxvZR4jICIWA4ur5s2rmr4EuKTMOszMrG/+ZbGZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeJKDQJJMyWtkLRS0pl9tOmQtEzScknXllmPmZltanRZK5Y0CrgAOBLoApZKWhQRdxbajAe+BsyMiPsl7VZWPWZmVluZewTTgZURsSoi1gMLgVlVbU4CLo+I+wEi4n9KrMfMzGooMwgmAGsK0135vKKXAC+Q1CnpFkknl1iPmZnVUNrQEKAa86LG4x8MHA6MBW6QdGNE3LPRiqQ5wByAtrY2Ojs7G19tg3V3dw/7OiuVpwGGfZ3QGv3ZKlqhL/3eHFplBkEXMKkwPRFYW6PNIxGxDlgn6TfAgcBGQRAR84H5AO3t7dHR0VFWzQ3T2dnJcK/zwhU3ANDRcWiTKxlYK/Rnq2iFvvR7c2iVOTS0FJgiaW9JY4DZwKKqNj8FDpM0WtJ2wCHAXSXWZGZmVUrbI4iIDZLmAkuAUcBFEbFc0un58nkRcZekq4HbgOeAb0bEHWXVZGZmmypzaIiIWAwsrpo3r2r688Dny6zDzMz65l8Wm5klzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpa4UoNA0kxJKyStlHRmjeUdkh6XtCz/O6vMeszMbFOjy1qxpFHABcCRQBewVNKiiLizqulvI+Kfy6rDzMz6V+YewXRgZUSsioj1wEJgVomPZ2Zmg1BmEEwA1hSmu/J51Q6VdKukqyQdUGI9ZmZWQ2lDQ4BqzIuq6T8Ae0VEt6Q3AD8BpmyyImkOMAegra2Nzs7OxlZagu7u7mFfZ6XyNMCwrxNaoz9bRSv0pd+bQ6vMIOgCJhWmJwJriw0i4onC7cWSviZpl4h4pKrdfGA+QHt7e3R0dJRWdKN0dnYy3Ou8cMUNAHR0HNrkSgbWCv3ZKlqhL/3eHFplDg0tBaZI2lvSGGA2sKjYQNLukpTfnp7X82iJNZmZWZXS9ggiYoOkucASYBRwUUQsl3R6vnwecDzwHkkbgKeB2RFRPXxkZmYlKnNoiIhYDCyumjevcPt84PwyazAzs/75l8VmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJa7uIJC0l6Qj8ttjJe1QXllmZjZU6goCSe8CfgR8PZ81key8QGZm1uLq3SN4H/Aa4AmAiPgTsFtZRZmZ2dCpNwieza8pAICk0Wx6JlEzM2tB9QbBtZL+HRgr6UjgMuDK8soyM7OhUm8QnAk8DNwOvJvs/EH/UVZRZmY2dOo96dxYsrOHfgOevx7xWOCpsgozM7OhUW8Q/Ao4AujOp8cCvwBeXUZRZlaOy+65jO8/9H0WXL2g2aX0a8VfZwBw6tXzm1zJwPb927500NHsMrZIvUGwbUT0hgD5pSW3K6kmMyvJ4lWLeWD9A4xnfLNL6dcrX3lts0uoy4q/rqCyVaXZZWyxeoNgnaSDIuIPAJIOJruQjJm1mAljJnDxzIubXcaIcOrVp1KpVJpdxharNwjOAC6T1HvN4T2AE0qpyMzMhlRdQRARSyXtD+wHCLg7Iv5WamVmZjYkNudSla8CJuf3eaUkIuLbpVRlZmZDpq4gkPQdYB9gGdCTzw7AQWBm1uLq3SNoB6ZGhE8rYWY2wtT7y+I7gN3LLMTMzJqj3j2CXYA7Jd0EPNs7MyLeVEpVZmY2ZOoNgrPLLMLMzJqn3q+PtsbP/MzMbLPVe4Wyf5C0VFK3pPWSeiQ9UXZxZmZWvnoPFp8PnAj8ieyEc6fl88zMrMXV/YOyiFgpaVRE9AAXS7q+xLrMzGyI1BsET0kaAyyT9DngQWBceWWZmdlQqXdo6G1527nAOmAS8C9lFWVmZkOn3iA4NiKeiYgnIuKciPgg8M8D3UnSTEkrJK2UdGY/7V6VH4A+vt7CzcysMeoNgrfXmHdKf3fIL2d5AXA0MBU4UdLUPtqdByypsxYzM2ugfo8RSDoROAnYW9KiwqIdgUcHWPd0YGVErMrXtRCYBdxZ1e7fgB+Tnd3UzMyG2EAHi68nOzC8C/DFwvwngdsGuO8EYE1hugs4pNhA0gTgOOD19BMEkuYAcwDa2tro7Owc4KGbr7u7e9jXWalkF5kb7nVCa/RnK6hUKvT09LgvG2Sk9Ge/QRAR9wH3SToCeDoinpP0EmB/4PYB1q1aq6ya/hLw0YjokWo1f76O+cB8gPb29ujo6BjgoZuvs7OT4V7nhStuAKCj49AmVzKwVujPVrDg6gVUKhX3ZYOMlP6s9+ujvwEOk/QC4FfAzWSXqnxLP/fpIvt2Ua+JwNqqNu3AwjwEdgHeIGlDRPykzrrMzGwL1XuwWBHxFNlXRr8aEceRHQDuz1JgiqS9898gzAaKxxmIiL0jYnJETAZ+BLzXIWBmNrTqDgJJh5LtAfw8nzfQsNIGst8dLAHuAi6NiOWSTpd0+mALNjOzxqp3aOgM4GPAFfmH+YuB/x7oThGxGFhcNW9eH21PqbMWMzNroM05DfW1helVwPvLKsrMzIbOQL8j+FJEnCHpSjb9xo+vUGZmNgIMtEfwnfzfL5RdiJmZNcdAB3xvyf+9VtKu+e2Hh6IwMzMbGv1+a0iZsyU9AtwN3CPpYUlnDU15ZmZWtoG+PnoG8BrgVRHxwoh4AdlpIl4j6QNlF2dmZuUbKAhOBk6MiNW9M/JvDL01X2ZmZi1uoCDYOiIeqZ6ZHyfYupySzMxsKA0UBOsHuczMzFrEQF8fPVDSEzXmC9i2hHrMzGyIDfT10VFDVYiZmTVHvSedMzOzEcpBYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniSg0CSTMlrZC0UtKZNZbPknSbpGWSbpb02jLrMTOzTfV78fotIWkUcAFwJNAFLJW0KCLuLDT7FbAoIkLSK4BLgf3LqsnMzDZVWhAA04GVEbEKQNJCYBbwfBBERHeh/TggSqxn6Nx8MdP++E1YPb7ZlfTvoVnZvxef29w66rDHNq8AOppdhtmIVGYQTADWFKa7gEOqG0k6DvgMsBvwxlorkjQHmAPQ1tZGZ2dno2ttqGl//CbjuldR4cXNLqVfX99xAQCVSnPrGMj23avZZeyjw/51bwWVSoWenh73ZYOMlP4sMwhUY94mW/wRcQVwhaTXAZ8CjqjRZj4wH6C9vT06OjoaW2mjrR5PhRcz/gO/a3YlI8PFb2RUpcKwf91bwIKrF1BxXzbMSOnPMg8WdwGTCtMTgbV9NY6I3wD7SNqlxJrMzKxKmUGwFJgiaW9JY4DZwKJiA0n7SlJ++yBgDPBoiTWZmVmV0oaGImKDpLnAEmAUcFFELJd0er58HvBm4GRJfwOeBk6IiJFxwNjMrEWUeYyAiFgMLK6aN69w+zzgvDJrMDOz/vmXxWZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklrtQgkDRT0gpJKyWdWWP5WyTdlv9dL+nAMusxM7NNlRYEkkYBFwBHA1OBEyVNrWq2GpgREa8APgXML6seMzOrrcw9gunAyohYFRHrgYXArGKDiLg+Ih7LJ28EJpZYj5mZ1TC6xHVPANYUpruAQ/pp/07gqloLJM0B5gC0tbXR2dnZoBLLMa1SoaenZ9jX2Srcn41TcV821EjpzzKDQDXmRc2G0j+SBcFray2PiPnkw0bt7e3R0dHRoBJLsno8lUqFYV9nq3B/NsyCqxe4LxtopPRnmUHQBUwqTE8E1lY3kvQK4JvA0RHxaIn1mJlZDWUeI1gKTJG0t6QxwGxgUbGBpD2By4G3RcQ9JdZiZmZ9KG2PICI2SJoLLAFGARdFxHJJp+fL5wFnAS8EviYJYENEtJdVk5mZbarMoSEiYjGwuGrevMLt04DTyqzBzMz6518Wm5klzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpa4UoNA0kxJKyStlHRmjeX7S7pB0rOSPlxmLWZmVtvoslYsaRRwAXAk0AUslbQoIu4sNPsr8H7g2LLqMDOz/pW5RzAdWBkRqyJiPbAQmFVsEBH/ExFLgb+VWIeZmfWjtD0CYAKwpjDdBRwymBVJmgPMAWhra6Ozs3OLiyvTtEqFnp6eYV9nq3B/Nk7FfdlQI6U/ywwC1ZgXg1lRRMwH5gO0t7dHR0fHFpQ1BFaPp1KpMOzrbBXuz4ZZcPUC92UDjZT+LHNoqAuYVJieCKwt8fHMzGwQygyCpcAUSXtLGgPMBhaV+HhmZjYIpQ0NRcQGSXOBJcAo4KKIWC7p9Hz5PEm7AzcDOwLPSToDmBoRT5RVl5mZbazMYwRExGJgcdW8eYXbD5ENGZmZWZP4l8VmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZokrNQgkzZS0QtJKSWfWWC5JX8mX3ybpoDLrMTOzTZUWBJJGARcARwNTgRMlTa1qdjQwJf+bA1xYVj1mZlZbmXsE04GVEbEqItYDC4FZVW1mAd+OzI3AeEl7lFiTmZlVKTMIJgBrCtNd+bzNbWNmZiUaXeK6VWNeDKINkuaQDR0BdEtasYW1DY0P1np6Nmjuz4bRie7LRmqR/tyrrwVlBkEXMKkwPRFYO4g2RMR8YH6jCzQzs3KHhpYCUyTtLWkMMBtYVNVmEXBy/u2hfwAej4gHS6zJzMyqlLZHEBEbJM0FlgCjgIsiYrmk0/Pl84DFwBuAlcBTwKll1WNmZrUpYpMheTMzS4h/WWxmljgHgZlZ4hwEZmaJcxA0mKSdJV0haZ2k+ySd1OyaWpWkuZJulvSspEuaXU+rk7SNpG/l78snJf1R0tHNrqtVSfqupAclPSHpHkmnNbumwSrzdwSpugBYD7QB04CfS7o1IpY3tarWtBY4FzgKGNvkWkaC0WS/5J8B3E/2jb1LJb08Iu5tZmEt6jPAOyPiWUn7A52S/hgRtzS7sM3lPYIGkjQOeDPwiYjojojryH4r8bbmVtaaIuLyiPgJ8GizaxkJImJdRJwdEfdGxHMR8TNgNXBws2trRRGxPCKe7Z3M//ZpYkmD5iBorJcAPRFxT2HercABTarHrE+S2sjes95bHSRJX5P0FHA38CDZb6NajoOgsbYHHq+a9ziwQxNqMeuTpK2B7wELIuLuZtfTqiLivWT/vw8DLgee7f8ew5ODoLG6gR2r5u0IPNmEWsxqkrQV8B2yY1lzm1xOy4uInnwYeCLwnmbXMxgOgsa6BxgtaUph3oF419uGCUkCvkX2ZYY3R8TfmlzSSDIaHyOwiFhHtnv4n5LGSXoN2cV3vtPcylqTpNGStiU7V9UoSdtK8jfdtsyFwEuBYyLi6WYX06ok7SZptqTtJY2SdBRwIvDrZtc2GD7XUINJ2hm4CDiS7NsuZ0bE95tbVWuSdDbwyarZ50TE2UNfTeuTtBdwL9k49obCondHxPeaUlSLkrQr8COyPf6tgPuAr0TEN5pa2CA5CMzMEuehITOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yCwEUXSREk/lfQnSX+W9GVJYySdIun8YVDfsZKmFqb/U9IRzazJzEFgI0Z++oTLgZ9ExBSyM2tuD3y6pMcbzK+cjwWeD4KIOCsiftmwoswGwUFgI8nrgWci4mLITgYGfAB4B7AdMEnS1ZJWSPokZNeQkPRzSbdKukPSCfn8gyVdK+kWSUsk7ZHP75T0X5KuBT4u6d78JG5I2k7SGklbS3qXpKX5en+cL3s18Cbg85KWSdpH0iWSjs/vf3h+1bDbJV0kaZt8/r2SzpH0h3zZ/vn8Gfl6luX381lubVAcBDaSHABsdHWoiHiC7Gpco4HpwFvIrhz3r5LagZnA2og4MCJeBlydn6L5q8DxEXEw2SlDinsV4yNiRkScQ3a9iRn5/GOAJfmJ3C6PiFdFxIHAXWRXsrqe7EJFH4mIaRHx594V5udUugQ4ISJentdbPJPlIxFxENm5gj6cz/sw8L6ImEZ2GmSfO8gGxUFgI4nIrhLV1/xrIuLR/GRrlwOvBW4HjpB0nqTDIuJxYD/gZcA1kpYB/0F2iuFeP6y6fUJ+e3Zh2csk/VbS7WThM9DFifYDVhcuarQAeF1h+eX5v7cAk/PbvwP+r6T3k4VT8fxBZnVzENhIshxoL86QtCMwCehh05CI/IP3YLJA+Iyks8iCY3m+1T4tIl4eEf9UuN+6wu1FwNH5yQYP5u9nn7wEmJtv3Z8DbDtA7Rpgee8FT3rIrzUeEZ8FTiO7nvONvUNGZpvLQWAjya+A7SSdDCBpFPBFsg/lp4AjJe0saSzZQdvfSXoR8FREfBf4AnAQsALYVdKh+Xq2llRziz4iuoGbgC8DP8uPS0B21aoH82GmtxTu8iS1r1h3NzBZ0r759NuAa/t7spL2iYjbI+I84GbAQWCD4iCwESOyU+keRzb+/yeyCwU9A/x73uQ6smtDLAN+HBE3Ay8HbsqHgD4OnBsR64HjgfMk3Zq3f3U/D/1D4K1sPGT0CeD3wDVkH/K9FgIfyQ/uPn8Rk4h4BjgVuCwfTnoOmDfAUz4jP8B9K9nxgasGaG9Wk09DbWaWOO8RmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmifv/7MFgO1jXWY4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.array([[0, 0.3, 0.4, 0.7],\n",
    "              [0.3, 0, 0.5, 0.8],\n",
    "              [0.4, 0.5, 0, 0.45],\n",
    "              [0.7, 0.8, 0.45, 0]])\n",
    "\n",
    "dis_X = X[np.triu_indices(X.shape[0],1)]\n",
    "Z = linkage(dis_X, 'complete')\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "dn = dendrogram(Z)\n",
    "\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Observations')\n",
    "plt.ylabel('Distance')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df09246d",
   "metadata": {},
   "source": [
    "#### (b) Repeat (a), this time using single linkage clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df8095de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Z = linkage(dis_X, 'single')\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "dn = dendrogram(Z)\n",
    "\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Observations')\n",
    "plt.ylabel('Distance')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f53ed87",
   "metadata": {},
   "source": [
    "#### (c) Suppose that we cut the dendrogram obtained in (a) such that two clusters result. Which observations are in each cluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254525d8",
   "metadata": {},
   "source": [
    "<strong>Answer</strong>\n",
    "One cluster will be (0,1), another cluster will be (2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4ba92d",
   "metadata": {},
   "source": [
    "#### (d) Suppose that we cut the dendrogram obtained in (b) such that two clusters result. Which observations are in each cluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd46a30a",
   "metadata": {},
   "source": [
    "<strong>Answer</strong>\n",
    "One cluster will be (3) , another cluster will be (2,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfba84e4",
   "metadata": {},
   "source": [
    "#### (e) It is mentioned in the chapter that at each fusion in the dendrogram, the position of the two clusters being fused can be swapped without changing the meaning of the dendrogram. Draw a dendrogram that is equivalent to the dendrogram in (a), for which two or more of the leaves are repositioned, but for which the meaning of the dendrogram is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ed97f95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.array([[0, 0.3, 0.4, 0.7],\n",
    "              [0.3, 0, 0.5, 0.8],\n",
    "              [0.4, 0.5, 0, 0.45],\n",
    "              [0.7, 0.8, 0.45, 0]])\n",
    "\n",
    "dis_X = X[np.triu_indices(X.shape[0],1)]\n",
    "Z = linkage(dis_X, 'complete')\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "dn = dendrogram(Z,labels=[2,3,0,1])\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Observations')\n",
    "plt.ylabel('Distance')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f010efb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
